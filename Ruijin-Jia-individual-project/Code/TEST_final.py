# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fXdAV29_oMMpVhYtwAY4_qhM44qJZswL
"""

import os
import cv2
import sys
import math
import time
import glob
import random
import warnings
import datetime
import itertools
import numpy as np
import pandas as pd
from PIL import Image
from tqdm.auto import tqdm
from google.colab import drive
from matplotlib import pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torchvision import datasets
from torch.autograd import Variable
from torchvision.utils import save_image
from torch.utils.data import DataLoader,Dataset

epoch = 0
n_epochs=100
dataset_name='test'
batch_size = 16
lr = 0.0005
b1 = 0.5
b2 = 0.999
decay_epoch = 100
n_cpu = 4
img_height = 256
img_width = 256
channels = 3
sample_interval = 100
checkpoint_interval = 338

warnings.filterwarnings('ignore')
DATA_DIR = os.getcwd()

class ImageDataset_color(Dataset):
  def __init__(self,root,transforms_=None,mode="train"):
    self.transform = transforms.Compose(transforms_)#transform
    self.files = sorted(glob.glob(root+"/*.*"))#dir
  def __getitem__(self,index):
    img_A = Image.fromarray(np.array(cv2.cvtColor(cv2.imread(self.files[index%len(self.files)]),cv2.COLOR_BGR2RGB)), "RGB")
    img_B = Image.fromarray(np.array(cv2.cvtColor(cv2.cvtColor(cv2.cvtColor(cv2.imread(self.files[index%len(self.files)]),cv2.COLOR_BGR2RGB),cv2.COLOR_RGB2GRAY),cv2.COLOR_GRAY2RGB)), "RGB")
    img_A = self.transform(img_A)
    img_B = self.transform(img_B)       
    return {"A":img_A,"B":img_B}
  def __len__(self):
    return len(self.files)

transforms_=[transforms.Resize((256,256), Image.BICUBIC),transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]


class UNetDown(nn.Module):
  def __init__(self, in_size, out_size, normalize=True, dropout=0.0):
      super(UNetDown, self).__init__()
      layers = [nn.Conv2d(in_size, out_size, 4, 2, 1, bias=False)]
      if normalize:
          layers.append(nn.InstanceNorm2d(out_size))
      layers.append(nn.LeakyReLU(0.2))
      if dropout:
          layers.append(nn.Dropout(dropout))
      self.model = nn.Sequential(*layers)
  def forward(self, x):
      return self.model(x)
class UNetUp(nn.Module):
  def __init__(self, in_size, out_size, dropout=0.0):
      super(UNetUp, self).__init__()
      layers = [nn.ConvTranspose2d(in_size, out_size, 4, 2, 1, bias=False),nn.InstanceNorm2d(out_size),nn.ReLU(inplace=True),]
      if dropout:
          layers.append(nn.Dropout(dropout))
      self.model = nn.Sequential(*layers)
  def forward(self, x, skip_input):
      x = self.model(x)
      x = torch.cat((x, skip_input), 1)
      return x
class GeneratorUNet(nn.Module):
  def __init__(self, in_channels=3, out_channels=3):
      super(GeneratorUNet, self).__init__()
      self.down1 = UNetDown(in_channels, 64, normalize=False)
      self.down2 = UNetDown(64, 128)
      self.down3 = UNetDown(128, 256)
      self.down4 = UNetDown(256, 512, dropout=0.5)
      self.down5 = UNetDown(512, 512, dropout=0.5)
      self.down6 = UNetDown(512, 512, dropout=0.5)
      self.down7 = UNetDown(512, 512, dropout=0.5)
      self.down8 = UNetDown(512, 512, normalize=False, dropout=0.5)
      self.up1 = UNetUp(512, 512, dropout=0.5)
      self.up2 = UNetUp(1024, 512, dropout=0.5)
      self.up3 = UNetUp(1024, 512, dropout=0.5)
      self.up4 = UNetUp(1024, 512, dropout=0.5)
      self.up5 = UNetUp(1024, 256)
      self.up6 = UNetUp(512, 128)
      self.up7 = UNetUp(256, 64)
      self.final = nn.Sequential(
          nn.Upsample(scale_factor=2),
          nn.ZeroPad2d((1, 0, 1, 0)),
          nn.Conv2d(128, out_channels, 4, padding=1),
          nn.Tanh(),)
  def forward(self, x):
      # U-Net generator with skip connections from encoder to decoder
      d1 = self.down1(x)
      d2 = self.down2(d1)
      d3 = self.down3(d2)
      d4 = self.down4(d3)
      d5 = self.down5(d4)
      d6 = self.down6(d5)
      d7 = self.down7(d6)
      d8 = self.down8(d7)
      u1 = self.up1(d8,d7)
      u2 = self.up2(u1,d6)
      u3 = self.up3(u2,d5)
      u4 = self.up4(u3,d4)
      u5 = self.up5(u4,d3)
      u6 = self.up6(u5,d2)
      u7 = self.up7(u6,d1)
      return self.final(u7)

cuda = True if torch.cuda.is_available() else False
Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor

lambda_pixel = 100 #

# # Calculate output of image discriminator (PatchGAN)
patch = (1,16,16) #(1,16,16),img_height // 2 ** 4, img_width // 2 ** 4


gpu = 0
device = torch.device("cpu")
#model = 'colorize_gan_{}.pth.tar'.format(epoch - 1)
generator = GeneratorUNet()
generator = generator.cuda()
generator.load_state_dict(torch.load(DATA_DIR+"/generator_99.pth"))
#G = GeneratorUNet(gpu).to(device)
#generator.load_state_dict(torch.load(model, map_location={'cuda:0': 'cpu'})['G'])

test_path="../Data/Train_1"
dataloader_test=DataLoader(ImageDataset_color(test_path,transforms_=transforms_),batch_size=2,num_workers=4,)
#for epoch in range(epoch,n_epochs):

C=ImageDataset_color(test_path,transforms_=transforms_)

for i, batch in enumerate(dataloader_test):
  real_A = Variable(batch["B"].type(Tensor))
  fake_B = generator(real_A)

fake_B -=fake_B.min()
fake_B/=fake_B.max()
B=np.transpose(fake_B.cpu().detach().numpy(), (0,2,3,1))

plt.imshow(B[0,...])

